{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2UBG1dPTv3vk0AHHVyr9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiena2cva/yolo3_pet/blob/master/colab/get_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e327KGUgt2VN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "1795e6a5-7cb4-4728-9369-360ed5ecd75e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-FzYHuCu9Yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fe9e6a36-6278-4e42-8f08-8bd10fa9534b"
      },
      "source": [
        "!git clone https://github.com/tiena2cva/yolo3_pet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolo3_pet'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 18 (delta 4), reused 13 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:   5% (1/18)   \rUnpacking objects:  11% (2/18)   \rUnpacking objects:  16% (3/18)   \rUnpacking objects:  22% (4/18)   \rUnpacking objects:  27% (5/18)   \rUnpacking objects:  33% (6/18)   \rUnpacking objects:  38% (7/18)   \rUnpacking objects:  44% (8/18)   \rUnpacking objects:  50% (9/18)   \rUnpacking objects:  55% (10/18)   \rUnpacking objects:  61% (11/18)   \rUnpacking objects:  66% (12/18)   \rUnpacking objects:  72% (13/18)   \rUnpacking objects:  77% (14/18)   \rUnpacking objects:  83% (15/18)   \rUnpacking objects:  88% (16/18)   \rUnpacking objects:  94% (17/18)   \rUnpacking objects: 100% (18/18)   \rUnpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K36RXdtmyR5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e78c16aa-9b72-4fe7-9fca-ffa82bd77161"
      },
      "source": [
        "%cd yolo3_pet"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolo3_pet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPtqgeyuwqfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3cd8d0d1-6f59-4cb3-d0dc-d51211a8be85"
      },
      "source": [
        "git submodule init && git submodule update"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submodule 'keras-yolo3' (https://github.com/tiena2cva/keras-yolo3) registered for path 'keras-yolo3'\n",
            "Cloning into '/content/yolo3_pet/keras-yolo3'...\n",
            "Submodule path 'keras-yolo3': checked out '47cb3cc689dfaee0fef1f57eaed69a9f93b72bb0'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8huZXSfwB5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1f7d3cf-f6b3-4a13-a529-d72349b13e77"
      },
      "source": [
        "./scripts/get_data.sh"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-12 12:41:31--  http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/x-gzip]\n",
            "Saving to: ‘images.tar.gz’\n",
            "\n",
            "images.tar.gz       100%[===================>] 755.23M  22.2MB/s    in 35s     \n",
            "\n",
            "2020-01-12 12:42:06 (21.6 MB/s) - ‘images.tar.gz’ saved [791918971/791918971]\n",
            "\n",
            "--2020-01-12 12:42:14--  http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173078 (18M) [application/x-gzip]\n",
            "Saving to: ‘annotations.tar.gz’\n",
            "\n",
            "annotations.tar.gz  100%[===================>]  18.28M  10.6MB/s    in 1.7s    \n",
            "\n",
            "2020-01-12 12:42:17 (10.6 MB/s) - ‘annotations.tar.gz’ saved [19173078/19173078]\n",
            "\n",
            "--2020-01-12 12:42:17--  https://pjreddie.com/media/files/darknet53.conv.74\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162482580 (155M) [application/octet-stream]\n",
            "Saving to: ‘pretrained/darknet53.weights’\n",
            "\n",
            "pretrained/darknet5 100%[===================>] 154.96M  27.9MB/s    in 5.8s    \n",
            "\n",
            "2020-01-12 12:42:23 (26.6 MB/s) - ‘pretrained/darknet53.weights’ saved [162482580/162482580]\n",
            "\n",
            "Using TensorFlow backend.\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [0]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-12 12:42:26.222119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-01-12 12:42:26.226895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x144cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-12 12:42:26.227010: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-12 12:42:26.257524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-12 12:42:26.312136: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-01-12 12:42:26.312243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eb3d40244eeb): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (1, 1, 64, 32)\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_13\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_15\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_17\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_19\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_21\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_23\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_25\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_27\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_28\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_30\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_32\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_34\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_36\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_38\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_40\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_42\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_44\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_45\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_47\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_49\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_51\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_22\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
            "                                                                 leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
            "                                                                 leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
            "                                                                 leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
            "                                                                 leaky_re_lu_52[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 40,620,640\n",
            "Trainable params: 40,584,928\n",
            "Non-trainable params: 35,712\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Saved Keras weights to pretrained/darknet53.h5\n",
            "Read 40620640 of 40620640.0 from Darknet weights.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMBrKOHysMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "e4f4de3a-15f0-4e46-b326-59d4e43b179f"
      },
      "source": [
        "!python gen_dataset.py"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class boxer: 100 images\n",
            "class saint_bernard: 99 images\n",
            "class samoyed: 99 images\n",
            "class english_cocker_spaniel: 100 images\n",
            "class leonberger: 100 images\n",
            "class staffordshire_bull_terrier: 100 images\n",
            "class english_setter: 100 images\n",
            "class german_shorthaired: 100 images\n",
            "class japanese_chin: 100 images\n",
            "class keeshond: 100 images\n",
            "class newfoundland: 100 images\n",
            "class scottish_terrier: 100 images\n",
            "class egyptian_mau: 92 images\n",
            "class chihuahua: 100 images\n",
            "class persian: 100 images\n",
            "class havanese: 100 images\n",
            "class bengal: 98 images\n",
            "class shiba_inu: 100 images\n",
            "class beagle: 100 images\n",
            "class abyssinian: 99 images\n",
            "class maine_coon: 100 images\n",
            "class russian_blue: 100 images\n",
            "class yorkshire_terrier: 100 images\n",
            "class birman: 100 images\n",
            "class miniature_pinscher: 100 images\n",
            "class sphynx: 100 images\n",
            "class american_pit_bull_terrier: 100 images\n",
            "class bombay: 100 images\n",
            "class pomeranian: 100 images\n",
            "class pug: 100 images\n",
            "class great_pyrenees: 100 images\n",
            "class basset_hound: 100 images\n",
            "class british_shorthair: 100 images\n",
            "class wheaten_terrier: 100 images\n",
            "class american_bulldog: 100 images\n",
            "class siamese: 100 images\n",
            "class ragdoll: 99 images\n",
            "1/3686\r2/3686\r3/3686\r4/3686\r5/3686\r6/3686\r7/3686\r8/3686\r9/3686\r10/3686\r11/3686\r12/3686\r13/3686\r14/3686\r15/3686\r16/3686\r17/3686\r18/3686\r19/3686\r20/3686\r21/3686\r22/3686\r23/3686\r24/3686\r25/3686\r26/3686\r27/3686\r28/3686\r29/3686\r30/3686\r31/3686\r32/3686\r33/3686\r34/3686\r35/3686\r36/3686\r37/3686\r38/3686\r39/3686\r40/3686\r41/3686\r42/3686\r43/3686\r44/3686\r45/3686\r46/3686\r47/3686\r48/3686\r49/3686\r50/3686\r51/3686\r52/3686\r53/3686\r54/3686\r55/3686\r56/3686\r57/3686\r58/3686\r59/3686\r60/3686\r61/3686\r62/3686\r63/3686\r64/3686\r65/3686\r66/3686\r67/3686\r68/3686\r69/3686\r70/3686\r71/3686\r72/3686\r73/3686\r74/3686\r75/3686\r76/3686\r77/3686\r78/3686\r79/3686\r80/3686\r81/3686\r82/3686\r83/3686\r84/3686\r85/3686\r86/3686\r87/3686\r88/3686\r89/3686\r90/3686\r91/3686\r92/3686\r93/3686\r94/3686\r95/3686\r96/3686\r97/3686\r98/3686\r99/3686\r100/3686\r101/3686\r102/3686\r103/3686\r104/3686\r105/3686\r106/3686\r107/3686\r108/3686\r109/3686\r110/3686\r111/3686\r112/3686\r113/3686\r114/3686\r115/3686\r116/3686\r117/3686\r118/3686\r119/3686\r120/3686\r121/3686\r122/3686\r123/3686\r124/3686\r125/3686\r126/3686\r127/3686\r128/3686\r129/3686\r130/3686\r131/3686\r132/3686\r133/3686\r134/3686\r135/3686\r136/3686\r137/3686\r138/3686\r139/3686\r140/3686\r141/3686\r142/3686\r143/3686\r144/3686\r145/3686\r146/3686\r147/3686\r148/3686\r149/3686\r150/3686\r151/3686\r152/3686\r153/3686\r154/3686\r155/3686\r156/3686\r157/3686\r158/3686\r159/3686\r160/3686\r161/3686\r162/3686\r163/3686\r164/3686\r165/3686\r166/3686\r167/3686\r168/3686\r169/3686\r170/3686\r171/3686\r172/3686\r173/3686\r174/3686\r175/3686\r176/3686\r177/3686\r178/3686\r179/3686\r180/3686\r181/3686\r182/3686\r183/3686\r184/3686\r185/3686\r186/3686\r187/3686\r188/3686\r189/3686\r190/3686\r191/3686\r192/3686\r193/3686\r194/3686\r195/3686\r196/3686\r197/3686\r198/3686\r199/3686\r200/3686\r201/3686\r202/3686\r203/3686\r204/3686\r205/3686\r206/3686\r207/3686\r208/3686\r209/3686\r210/3686\r211/3686\r212/3686\r213/3686\r214/3686\r215/3686\r216/3686\r217/3686\r218/3686\r219/3686\r220/3686\r221/3686\r222/3686\r223/3686\r224/3686\r225/3686\r226/3686\r227/3686\r228/3686\r229/3686\r230/3686\r231/3686\r232/3686\r233/3686\r234/3686\r235/3686\r236/3686\r237/3686\r238/3686\r239/3686\r240/3686\r241/3686\r242/3686\r243/3686\r244/3686\r245/3686\r246/3686\r247/3686\r248/3686\r249/3686\r250/3686\r251/3686\r252/3686\r253/3686\r254/3686\r255/3686\r256/3686\r257/3686\r258/3686\r259/3686\r260/3686\r261/3686\r262/3686\r263/3686\r264/3686\r265/3686\r266/3686\r267/3686\r268/3686\r269/3686\r270/3686\r271/3686\r272/3686\r273/3686\r274/3686\r275/3686\r276/3686\r277/3686\r278/3686\r279/3686\r280/3686\r281/3686\r282/3686\r283/3686\r284/3686\r285/3686\r286/3686\r287/3686\r288/3686\r289/3686\r290/3686\r291/3686\r292/3686\r293/3686\r294/3686\r295/3686\r296/3686\r297/3686\r298/3686\r299/3686\r300/3686\r301/3686\r302/3686\r303/3686\r304/3686\r305/3686\r306/3686\r307/3686\r308/3686\r309/3686\r310/3686\r311/3686\r312/3686\r313/3686\r314/3686\r315/3686\r316/3686\r317/3686\r318/3686\r319/3686\r320/3686\r321/3686\r322/3686\r323/3686\r324/3686\r325/3686\r326/3686\r327/3686\r328/3686\r329/3686\r330/3686\r331/3686\r332/3686\r333/3686\r334/3686\r335/3686\r336/3686\r337/3686\r338/3686\r339/3686\r340/3686\r341/3686\r342/3686\r343/3686\r344/3686\r345/3686\r346/3686\r347/3686\r348/3686\r349/3686\r350/3686\r351/3686\r352/3686\r353/3686\r354/3686\r355/3686\r356/3686\r357/3686\r358/3686\r359/3686\r360/3686\r361/3686\r362/3686\r363/3686\r364/3686\r365/3686\r366/3686\r367/3686\r368/3686\r369/3686\r370/3686\r371/3686\r372/3686\r373/3686\r374/3686\r375/3686\r376/3686\r377/3686\r378/3686\r379/3686\r380/3686\r381/3686\r382/3686\r383/3686\r384/3686\r385/3686\r386/3686\r387/3686\r388/3686\r389/3686\r390/3686\r391/3686\r392/3686\r393/3686\r394/3686\r395/3686\r396/3686\r397/3686\r398/3686\r399/3686\r400/3686\r401/3686\r402/3686\r403/3686\r404/3686\r405/3686\r406/3686\r407/3686\r408/3686\r409/3686\r410/3686\r411/3686\r412/3686\r413/3686\r414/3686\r415/3686\r416/3686\r417/3686\r418/3686\r419/3686\r420/3686\r421/3686\r422/3686\r423/3686\r424/3686\r425/3686\r426/3686\r427/3686\r428/3686\r429/3686\r430/3686\r431/3686\r432/3686\r433/3686\r434/3686\r435/3686\r436/3686\r437/3686\r438/3686\r439/3686\r440/3686\r441/3686\r442/3686\r443/3686\r444/3686\r445/3686\r446/3686\r447/3686\r448/3686\r449/3686\r450/3686\r451/3686\r452/3686\r453/3686\r454/3686\r455/3686\r456/3686\r457/3686\r458/3686\r459/3686\r460/3686\r461/3686\r462/3686\r463/3686\r464/3686\r465/3686\r466/3686\r467/3686\r468/3686\r469/3686\r470/3686\r471/3686\r472/3686\r473/3686\r474/3686\r475/3686\r476/3686\r477/3686\r478/3686\r479/3686\r480/3686\r481/3686\r482/3686\r483/3686\r484/3686\r485/3686\r486/3686\r487/3686\r488/3686\r489/3686\r490/3686\r491/3686\r492/3686\r493/3686\r494/3686\r495/3686\r496/3686\r497/3686\r498/3686\r499/3686\r500/3686\r501/3686\r502/3686\r503/3686\r504/3686\r505/3686\r506/3686\r507/3686\r508/3686\r509/3686\r510/3686\r511/3686\r512/3686\r513/3686\r514/3686\r515/3686\r516/3686\r517/3686\r518/3686\r519/3686\r520/3686\r521/3686\r522/3686\r523/3686\r524/3686\r525/3686\r526/3686\r527/3686\r528/3686\r529/3686\r530/3686\r531/3686\r532/3686\r533/3686\r534/3686\r535/3686\r536/3686\r537/3686\r538/3686\r539/3686\r540/3686\r541/3686\r542/3686\r543/3686\r544/3686\r545/3686\r546/3686\r547/3686\r548/3686\r549/3686\r550/3686\r551/3686\r552/3686\r553/3686\r554/3686\r555/3686\r556/3686\r557/3686\r558/3686\r559/3686\r560/3686\r561/3686\r562/3686\r563/3686\r564/3686\r565/3686\r566/3686\r567/3686\r568/3686\r569/3686\r570/3686\r571/3686\r572/3686\r573/3686\r574/3686\r575/3686\r576/3686\r577/3686\r578/3686\r579/3686\r580/3686\r581/3686\r582/3686\r583/3686\r584/3686\r585/3686\r586/3686\r587/3686\r588/3686\r589/3686\r590/3686\r591/3686\r592/3686\r593/3686\r594/3686\r595/3686\r596/3686\r597/3686\r598/3686\r599/3686\r600/3686\r601/3686\r602/3686\r603/3686\r604/3686\r605/3686\r606/3686\r607/3686\r608/3686\r609/3686\r610/3686\r611/3686\r612/3686\r613/3686\r614/3686\r615/3686\r616/3686\r617/3686\r618/3686\r619/3686\r620/3686\r621/3686\r622/3686\r623/3686\r624/3686\r625/3686\r626/3686\r627/3686\r628/3686\r629/3686\r630/3686\r631/3686\r632/3686\r633/3686\r634/3686\r635/3686\r636/3686\r637/3686\r638/3686\r639/3686\r640/3686\r641/3686\r642/3686\r643/3686\r644/3686\r645/3686\r646/3686\r647/3686\r648/3686\r649/3686\r650/3686\r651/3686\r652/3686\r653/3686\r654/3686\r655/3686\r656/3686\r657/3686\r658/3686\r659/3686\r660/3686\r661/3686\r662/3686\r663/3686\r664/3686\r665/3686\r666/3686\r667/3686\r668/3686\r669/3686\r670/3686\r671/3686\r672/3686\r673/3686\r674/3686\r675/3686\r676/3686\r677/3686\r678/3686\r679/3686\r680/3686\r681/3686\r682/3686\r683/3686\r684/3686\r685/3686\r686/3686\r687/3686\r688/3686\r689/3686\r690/3686\r691/3686\r692/3686\r693/3686\r694/3686\r695/3686\r696/3686\r697/3686\r698/3686\r699/3686\r700/3686\r701/3686\r702/3686\r703/3686\r704/3686\r705/3686\r706/3686\r707/3686\r708/3686\r709/3686\r710/3686\r711/3686\r712/3686\r713/3686\r714/3686\r715/3686\r716/3686\r717/3686\r718/3686\r719/3686\r720/3686\r721/3686\r722/3686\r723/3686\r724/3686\r725/3686\r726/3686\r727/3686\r728/3686\r729/3686\r730/3686\r731/3686\r732/3686\r733/3686\r734/3686\r735/3686\r736/3686\r737/3686\r738/3686\r739/3686\r740/3686\r741/3686\r742/3686\r743/3686\r744/3686\r745/3686\r746/3686\r747/3686\r748/3686\r749/3686\r750/3686\r751/3686\r752/3686\r753/3686\r754/3686\r755/3686\r756/3686\r757/3686\r758/3686\r759/3686\r760/3686\r761/3686\r762/3686\r763/3686\r764/3686\r765/3686\r766/3686\r767/3686\r768/3686\r769/3686\r770/3686\r771/3686\r772/3686\r773/3686\r774/3686\r775/3686\r776/3686\r777/3686\r778/3686\r779/3686\r780/3686\r781/3686\r782/3686\r783/3686\r784/3686\r785/3686\r786/3686\r787/3686\r788/3686\r789/3686\r790/3686\r791/3686\r792/3686\r793/3686\r794/3686\r795/3686\r796/3686\r797/3686\r798/3686\r799/3686\r800/3686\r801/3686\r802/3686\r803/3686\r804/3686\r805/3686\r806/3686\r807/3686\r808/3686\r809/3686\r810/3686\r811/3686\r812/3686\r813/3686\r814/3686\r815/3686\r816/3686\r817/3686\r818/3686\r819/3686\r820/3686\r821/3686\r822/3686\r823/3686\r824/3686\r825/3686\r826/3686\r827/3686\r828/3686\r829/3686\r830/3686\r831/3686\r832/3686\r833/3686\r834/3686\r835/3686\r836/3686\r837/3686\r838/3686\r839/3686\r840/3686\r841/3686\r842/3686\r843/3686\r844/3686\r845/3686\r846/3686\r847/3686\r848/3686\r849/3686\r850/3686\r851/3686\r852/3686\r853/3686\r854/3686\r855/3686\r856/3686\r857/3686\r858/3686\r859/3686\r860/3686\r861/3686\r862/3686\r863/3686\r864/3686\r865/3686\r866/3686\r867/3686\r868/3686\r869/3686\r870/3686\r871/3686\r872/3686\r873/3686\r874/3686\r875/3686\r876/3686\r877/3686\r878/3686\r879/3686\r880/3686\r881/3686\r882/3686\r883/3686\r884/3686\r885/3686\r886/3686\r887/3686\r888/3686\r889/3686\r890/3686\r891/3686\r892/3686\r893/3686\r894/3686\r895/3686\r896/3686\r897/3686\r898/3686\r899/3686\r900/3686\r901/3686\r902/3686\r903/3686\r904/3686\r905/3686\r906/3686\r907/3686\r908/3686\r909/3686\r910/3686\r911/3686\r912/3686\r913/3686\r914/3686\r915/3686\r916/3686\r917/3686\r918/3686\r919/3686\r920/3686\r921/3686\r922/3686\r923/3686\r924/3686\r925/3686\r926/3686\r927/3686\r928/3686\r929/3686\r930/3686\r931/3686\r932/3686\r933/3686\r934/3686\r935/3686\r936/3686\r937/3686\r938/3686\r939/3686\r940/3686\r941/3686\r942/3686\r943/3686\r944/3686\r945/3686\r946/3686\r947/3686\r948/3686\r949/3686\r950/3686\r951/3686\r952/3686\r953/3686\r954/3686\r955/3686\r956/3686\r957/3686\r958/3686\r959/3686\r960/3686\r961/3686\r962/3686\r963/3686\r964/3686\r965/3686\r966/3686\r967/3686\r968/3686\r969/3686\r970/3686\r971/3686\r972/3686\r973/3686\r974/3686\r975/3686\r976/3686\r977/3686\r978/3686\r979/3686\r980/3686\r981/3686\r982/3686\r983/3686\r984/3686\r985/3686\r986/3686\r987/3686\r988/3686\r989/3686\r990/3686\r991/3686\r992/3686\r993/3686\r994/3686\r995/3686\r996/3686\r997/3686\r998/3686\r999/3686\r1000/3686\r1001/3686\r1002/3686\r1003/3686\r1004/3686\r1005/3686\r1006/3686\r1007/3686\r1008/3686\r1009/3686\r1010/3686\r1011/3686\r1012/3686\r1013/3686\r1014/3686\r1015/3686\r1016/3686\r1017/3686\r1018/3686\r1019/3686\r1020/3686\r1021/3686\r1022/3686\r1023/3686\r1024/3686\r1025/3686\r1026/3686\r1027/3686\r1028/3686\r1029/3686\r1030/3686\r1031/3686\r1032/3686\r1033/3686\r1034/3686\r1035/3686\r1036/3686\r1037/3686\r1038/3686\r1039/3686\r1040/3686\r1041/3686\r1042/3686\r1043/3686\r1044/3686\r1045/3686\r1046/3686\r1047/3686\r1048/3686\r1049/3686\r1050/3686\r1051/3686\r1052/3686\r1053/3686\r1054/3686\r1055/3686\r1056/3686\r1057/3686\r1058/3686\r1059/3686\r1060/3686\r1061/3686\r1062/3686\r1063/3686\r1064/3686\r1065/3686\r1066/3686\r1067/3686\r1068/3686\r1069/3686\r1070/3686\r1071/3686\r1072/3686\r1073/3686\r1074/3686\r1075/3686\r1076/3686\r1077/3686\r1078/3686\r1079/3686\r1080/3686\r1081/3686\r1082/3686\r1083/3686\r1084/3686\r1085/3686\r1086/3686\r1087/3686\r1088/3686\r1089/3686\r1090/3686\r1091/3686\r1092/3686\r1093/3686\r1094/3686\r1095/3686\r1096/3686\r1097/3686\r1098/3686\r1099/3686\r1100/3686\r1101/3686\r1102/3686\r1103/3686\r1104/3686\r1105/3686\r1106/3686\r1107/3686\r1108/3686\r1109/3686\r1110/3686\r1111/3686\r1112/3686\r1113/3686\r1114/3686\r1115/3686\r1116/3686\r1117/3686\r1118/3686\r1119/3686\r1120/3686\r1121/3686\r1122/3686\r1123/3686\r1124/3686\r1125/3686\r1126/3686\r1127/3686\r1128/3686\r1129/3686\r1130/3686\r1131/3686\r1132/3686\r1133/3686\r1134/3686\r1135/3686\r1136/3686\r1137/3686\r1138/3686\r1139/3686\r1140/3686\r1141/3686\r1142/3686\r1143/3686\r1144/3686\r1145/3686\r1146/3686\r1147/3686\r1148/3686\r1149/3686\r1150/3686\r1151/3686\r1152/3686\r1153/3686\r1154/3686\r1155/3686\r1156/3686\r1157/3686\r1158/3686\r1159/3686\r1160/3686\r1161/3686\r1162/3686\r1163/3686\r1164/3686\r1165/3686\r1166/3686\r1167/3686\r1168/3686\r1169/3686\r1170/3686\r1171/3686\r1172/3686\r1173/3686\r1174/3686\r1175/3686\r1176/3686\r1177/3686\r1178/3686\r1179/3686\r1180/3686\r1181/3686\r1182/3686\r1183/3686\r1184/3686\r1185/3686\r1186/3686\r1187/3686\r1188/3686\r1189/3686\r1190/3686\r1191/3686\r1192/3686\r1193/3686\r1194/3686\r1195/3686\r1196/3686\r1197/3686\r1198/3686\r1199/3686\r1200/3686\r1201/3686\r1202/3686\r1203/3686\r1204/3686\r1205/3686\r1206/3686\r1207/3686\r1208/3686\r1209/3686\r1210/3686\r1211/3686\r1212/3686\r1213/3686\r1214/3686\r1215/3686\r1216/3686\r1217/3686\r1218/3686\r1219/3686\r1220/3686\r1221/3686\r1222/3686\r1223/3686\r1224/3686\r1225/3686\r1226/3686\r1227/3686\r1228/3686\r1229/3686\r1230/3686\r1231/3686\r1232/3686\r1233/3686\r1234/3686\r1235/3686\r1236/3686\r1237/3686\r1238/3686\r1239/3686\r1240/3686\r1241/3686\r1242/3686\r1243/3686\r1244/3686\r1245/3686\r1246/3686\r1247/3686\r1248/3686\r1249/3686\r1250/3686\r1251/3686\r1252/3686\r1253/3686\r1254/3686\r1255/3686\r1256/3686\r1257/3686\r1258/3686\r1259/3686\r1260/3686\r1261/3686\r1262/3686\r1263/3686\r1264/3686\r1265/3686\r1266/3686\r1267/3686\r1268/3686\r1269/3686\r1270/3686\r1271/3686\r1272/3686\r1273/3686\r1274/3686\r1275/3686\r1276/3686\r1277/3686\r1278/3686\r1279/3686\r1280/3686\r1281/3686\r1282/3686\r1283/3686\r1284/3686\r1285/3686\r1286/3686\r1287/3686\r1288/3686\r1289/3686\r1290/3686\r1291/3686\r1292/3686\r1293/3686\r1294/3686\r1295/3686\r1296/3686\r1297/3686\r1298/3686\r1299/3686\r1300/3686\r1301/3686\r1302/3686\r1303/3686\r1304/3686\r1305/3686\r1306/3686\r1307/3686\r1308/3686\r1309/3686\r1310/3686\r1311/3686\r1312/3686\r1313/3686\r1314/3686\r1315/3686\r1316/3686\r1317/3686\r1318/3686\r1319/3686\r1320/3686\r1321/3686\r1322/3686\r1323/3686\r1324/3686\r1325/3686\r1326/3686\r1327/3686\r1328/3686\r1329/3686\r1330/3686\r1331/3686\r1332/3686\r1333/3686\r1334/3686\r1335/3686\r1336/3686\r1337/3686\r1338/3686\r1339/3686\r1340/3686\r1341/3686\r1342/3686\r1343/3686\r1344/3686\r1345/3686\r1346/3686\r1347/3686\r1348/3686\r1349/3686\r1350/3686\r1351/3686\r1352/3686\r1353/3686\r1354/3686\r1355/3686\r1356/3686\r1357/3686\r1358/3686\r1359/3686\r1360/3686\r1361/3686\r1362/3686\r1363/3686\r1364/3686\r1365/3686\r1366/3686\r1367/3686\r1368/3686\r1369/3686\r1370/3686\r1371/3686\r1372/3686\r1373/3686\r1374/3686\r1375/3686\r1376/3686\r1377/3686\r1378/3686\r1379/3686\r1380/3686\r1381/3686\r1382/3686\r1383/3686\r1384/3686\r1385/3686\r1386/3686\r1387/3686\r1388/3686\r1389/3686\r1390/3686\r1391/3686\r1392/3686\r1393/3686\r1394/3686\r1395/3686\r1396/3686\r1397/3686\r1398/3686\r1399/3686\r1400/3686\r1401/3686\r1402/3686\r1403/3686\r1404/3686\r1405/3686\r1406/3686\r1407/3686\r1408/3686\r1409/3686\r1410/3686\r1411/3686\r1412/3686\r1413/3686\r1414/3686\r1415/3686\r1416/3686\r1417/3686\r1418/3686\r1419/3686\r1420/3686\r1421/3686\r1422/3686\r1423/3686\r1424/3686\r1425/3686\r1426/3686\r1427/3686\r1428/3686\r1429/3686\r1430/3686\r1431/3686\r1432/3686\r1433/3686\r1434/3686\r1435/3686\r1436/3686\r1437/3686\r1438/3686\r1439/3686\r1440/3686\r1441/3686\r1442/3686\r1443/3686\r1444/3686\r1445/3686\r1446/3686\r1447/3686\r1448/3686\r1449/3686\r1450/3686\r1451/3686\r1452/3686\r1453/3686\r1454/3686\r1455/3686\r1456/3686\r1457/3686\r1458/3686\r1459/3686\r1460/3686\r1461/3686\r1462/3686\r1463/3686\r1464/3686\r1465/3686\r1466/3686\r1467/3686\r1468/3686\r1469/3686\r1470/3686\r1471/3686\r1472/3686\r1473/3686\r1474/3686\r1475/3686\r1476/3686\r1477/3686\r1478/3686\r1479/3686\r1480/3686\r1481/3686\r1482/3686\r1483/3686\r1484/3686\r1485/3686\r1486/3686\r1487/3686\r1488/3686\r1489/3686\r1490/3686\r1491/3686\r1492/3686\r1493/3686\r1494/3686\r1495/3686\r1496/3686\r1497/3686\r1498/3686\r1499/3686\r1500/3686\r1501/3686\r1502/3686\r1503/3686\r1504/3686\r1505/3686\r1506/3686\r1507/3686\r1508/3686\r1509/3686\r1510/3686\r1511/3686\r1512/3686\r1513/3686\r1514/3686\r1515/3686\r1516/3686\r1517/3686\r1518/3686\r1519/3686\r1520/3686\r1521/3686\r1522/3686\r1523/3686\r1524/3686\r1525/3686\r1526/3686\r1527/3686\r1528/3686\r1529/3686\r1530/3686\r1531/3686\r1532/3686\r1533/3686\r1534/3686\r1535/3686\r1536/3686\r1537/3686\r1538/3686\r1539/3686\r1540/3686\r1541/3686\r1542/3686\r1543/3686\r1544/3686\r1545/3686\r1546/3686\r1547/3686\r1548/3686\r1549/3686\r1550/3686\r1551/3686\r1552/3686\r1553/3686\r1554/3686\r1555/3686\r1556/3686\r1557/3686\r1558/3686\r1559/3686\r1560/3686\r1561/3686\r1562/3686\r1563/3686\r1564/3686\r1565/3686\r1566/3686\r1567/3686\r1568/3686\r1569/3686\r1570/3686\r1571/3686\r1572/3686\r1573/3686\r1574/3686\r1575/3686\r1576/3686\r1577/3686\r1578/3686\r1579/3686\r1580/3686\r1581/3686\r1582/3686\r1583/3686\r1584/3686\r1585/3686\r1586/3686\r1587/3686\r1588/3686\r1589/3686\r1590/3686\r1591/3686\r1592/3686\r1593/3686\r1594/3686\r1595/3686\r1596/3686\r1597/3686\r1598/3686\r1599/3686\r1600/3686\r1601/3686\r1602/3686\r1603/3686\r1604/3686\r1605/3686\r1606/3686\r1607/3686\r1608/3686\r1609/3686\r1610/3686\r1611/3686\r1612/3686\r1613/3686\r1614/3686\r1615/3686\r1616/3686\r1617/3686\r1618/3686\r1619/3686\r1620/3686\r1621/3686\r1622/3686\r1623/3686\r1624/3686\r1625/3686\r1626/3686\r1627/3686\r1628/3686\r1629/3686\r1630/3686\r1631/3686\r1632/3686\r1633/3686\r1634/3686\r1635/3686\r1636/3686\r1637/3686\r1638/3686\r1639/3686\r1640/3686\r1641/3686\r1642/3686\r1643/3686\r1644/3686\r1645/3686\r1646/3686\r1647/3686\r1648/3686\r1649/3686\r1650/3686\r1651/3686\r1652/3686\r1653/3686\r1654/3686\r1655/3686\r1656/3686\r1657/3686\r1658/3686\r1659/3686\r1660/3686\r1661/3686\r1662/3686\r1663/3686\r1664/3686\r1665/3686\r1666/3686\r1667/3686\r1668/3686\r1669/3686\r1670/3686\r1671/3686\r1672/3686\r1673/3686\r1674/3686\r1675/3686\r1676/3686\r1677/3686\r1678/3686\r1679/3686\r1680/3686\r1681/3686\r1682/3686\r1683/3686\r1684/3686\r1685/3686\r1686/3686\r1687/3686\r1688/3686\r1689/3686\r1690/3686\r1691/3686\r1692/3686\r1693/3686\r1694/3686\r1695/3686\r1696/3686\r1697/3686\r1698/3686\r1699/3686\r1700/3686\r1701/3686\r1702/3686\r1703/3686\r1704/3686\r1705/3686\r1706/3686\r1707/3686\r1708/3686\r1709/3686\r1710/3686\r1711/3686\r1712/3686\r1713/3686\r1714/3686\r1715/3686\r1716/3686\r1717/3686\r1718/3686\r1719/3686\r1720/3686\r1721/3686\r1722/3686\r1723/3686\r1724/3686\r1725/3686\r1726/3686\r1727/3686\r1728/3686\r1729/3686\r1730/3686\r1731/3686\r1732/3686\r1733/3686\r1734/3686\r1735/3686\r1736/3686\r1737/3686\r1738/3686\r1739/3686\r1740/3686\r1741/3686\r1742/3686\r1743/3686\r1744/3686\r1745/3686\r1746/3686\r1747/3686\r1748/3686\r1749/3686\r1750/3686\r1751/3686\r1752/3686\r1753/3686\r1754/3686\r1755/3686\r1756/3686\r1757/3686\r1758/3686\r1759/3686\r1760/3686\r1761/3686\r1762/3686\r1763/3686\r1764/3686\r1765/3686\r1766/3686\r1767/3686\r1768/3686\r1769/3686\r1770/3686\r1771/3686\r1772/3686\r1773/3686\r1774/3686\r1775/3686\r1776/3686\r1777/3686\r1778/3686\r1779/3686\r1780/3686\r1781/3686\r1782/3686\r1783/3686\r1784/3686\r1785/3686\r1786/3686\r1787/3686\r1788/3686\r1789/3686\r1790/3686\r1791/3686\r1792/3686\r1793/3686\r1794/3686\r1795/3686\r1796/3686\r1797/3686\r1798/3686\r1799/3686\r1800/3686\r1801/3686\r1802/3686\r1803/3686\r1804/3686\r1805/3686\r1806/3686\r1807/3686\r1808/3686\r1809/3686\r1810/3686\r1811/3686\r1812/3686\r1813/3686\r1814/3686\r1815/3686\r1816/3686\r1817/3686\r1818/3686\r1819/3686\r1820/3686\r1821/3686\r1822/3686\r1823/3686\r1824/3686\r1825/3686\r1826/3686\r1827/3686\r1828/3686\r1829/3686\r1830/3686\r1831/3686\r1832/3686\r1833/3686\r1834/3686\r1835/3686\r1836/3686\r1837/3686\r1838/3686\r1839/3686\r1840/3686\r1841/3686\r1842/3686\r1843/3686\r1844/3686\r1845/3686\r1846/3686\r1847/3686\r1848/3686\r1849/3686\r1850/3686\r1851/3686\r1852/3686\r1853/3686\r1854/3686\r1855/3686\r1856/3686\r1857/3686\r1858/3686\r1859/3686\r1860/3686\r1861/3686\r1862/3686\r1863/3686\r1864/3686\r1865/3686\r1866/3686\r1867/3686\r1868/3686\r1869/3686\r1870/3686\r1871/3686\r1872/3686\r1873/3686\r1874/3686\r1875/3686\r1876/3686\r1877/3686\r1878/3686\r1879/3686\r1880/3686\r1881/3686\r1882/3686\r1883/3686\r1884/3686\r1885/3686\r1886/3686\r1887/3686\r1888/3686\r1889/3686\r1890/3686\r1891/3686\r1892/3686\r1893/3686\r1894/3686\r1895/3686\r1896/3686\r1897/3686\r1898/3686\r1899/3686\r1900/3686\r1901/3686\r1902/3686\r1903/3686\r1904/3686\r1905/3686\r1906/3686\r1907/3686\r1908/3686\r1909/3686\r1910/3686\r1911/3686\r1912/3686\r1913/3686\r1914/3686\r1915/3686\r1916/3686\r1917/3686\r1918/3686\r1919/3686\r1920/3686\r1921/3686\r1922/3686\r1923/3686\r1924/3686\r1925/3686\r1926/3686\r1927/3686\r1928/3686\r1929/3686\r1930/3686\r1931/3686\r1932/3686\r1933/3686\r1934/3686\r1935/3686\r1936/3686\r1937/3686\r1938/3686\r1939/3686\r1940/3686\r1941/3686\r1942/3686\r1943/3686\r1944/3686\r1945/3686\r1946/3686\r1947/3686\r1948/3686\r1949/3686\r1950/3686\r1951/3686\r1952/3686\r1953/3686\r1954/3686\r1955/3686\r1956/3686\r1957/3686\r1958/3686\r1959/3686\r1960/3686\r1961/3686\r1962/3686\r1963/3686\r1964/3686\r1965/3686\r1966/3686\r1967/3686\r1968/3686\r1969/3686\r1970/3686\r1971/3686\r1972/3686\r1973/3686\r1974/3686\r1975/3686\r1976/3686\r1977/3686\r1978/3686\r1979/3686\r1980/3686\r1981/3686\r1982/3686\r1983/3686\r1984/3686\r1985/3686\r1986/3686\r1987/3686\r1988/3686\r1989/3686\r1990/3686\r1991/3686\r1992/3686\r1993/3686\r1994/3686\r1995/3686\r1996/3686\r1997/3686\r1998/3686\r1999/3686\r2000/3686\r2001/3686\r2002/3686\r2003/3686\r2004/3686\r2005/3686\r2006/3686\r2007/3686\r2008/3686\r2009/3686\r2010/3686\r2011/3686\r2012/3686\r2013/3686\r2014/3686\r2015/3686\r2016/3686\r2017/3686\r2018/3686\r2019/3686\r2020/3686\r2021/3686\r2022/3686\r2023/3686\r2024/3686\r2025/3686\r2026/3686\r2027/3686\r2028/3686\r2029/3686\r2030/3686\r2031/3686\r2032/3686\r2033/3686\r2034/3686\r2035/3686\r2036/3686\r2037/3686\r2038/3686\r2039/3686\r2040/3686\r2041/3686\r2042/3686\r2043/3686\r2044/3686\r2045/3686\r2046/3686\r2047/3686\r2048/3686\r2049/3686\r2050/3686\r2051/3686\r2052/3686\r2053/3686\r2054/3686\r2055/3686\r2056/3686\r2057/3686\r2058/3686\r2059/3686\r2060/3686\r2061/3686\r2062/3686\r2063/3686\r2064/3686\r2065/3686\r2066/3686\r2067/3686\r2068/3686\r2069/3686\r2070/3686\r2071/3686\r2072/3686\r2073/3686\r2074/3686\r2075/3686\r2076/3686\r2077/3686\r2078/3686\r2079/3686\r2080/3686\r2081/3686\r2082/3686\r2083/3686\r2084/3686\r2085/3686\r2086/3686\r2087/3686\r2088/3686\r2089/3686\r2090/3686\r2091/3686\r2092/3686\r2093/3686\r2094/3686\r2095/3686\r2096/3686\r2097/3686\r2098/3686\r2099/3686\r2100/3686\r2101/3686\r2102/3686\r2103/3686\r2104/3686\r2105/3686\r2106/3686\r2107/3686\r2108/3686\r2109/3686\r2110/3686\r2111/3686\r2112/3686\r2113/3686\r2114/3686\r2115/3686\r2116/3686\r2117/3686\r2118/3686\r2119/3686\r2120/3686\r2121/3686\r2122/3686\r2123/3686\r2124/3686\r2125/3686\r2126/3686\r2127/3686\r2128/3686\r2129/3686\r2130/3686\r2131/3686\r2132/3686\r2133/3686\r2134/3686\r2135/3686\r2136/3686\r2137/3686\r2138/3686\r2139/3686\r2140/3686\r2141/3686\r2142/3686\r2143/3686\r2144/3686\r2145/3686\r2146/3686\r2147/3686\r2148/3686\r2149/3686\r2150/3686\r2151/3686\r2152/3686\r2153/3686\r2154/3686\r2155/3686\r2156/3686\r2157/3686\r2158/3686\r2159/3686\r2160/3686\r2161/3686\r2162/3686\r2163/3686\r2164/3686\r2165/3686\r2166/3686\r2167/3686\r2168/3686\r2169/3686\r2170/3686\r2171/3686\r2172/3686\r2173/3686\r2174/3686\r2175/3686\r2176/3686\r2177/3686\r2178/3686\r2179/3686\r2180/3686\r2181/3686\r2182/3686\r2183/3686\r2184/3686\r2185/3686\r2186/3686\r2187/3686\r2188/3686\r2189/3686\r2190/3686\r2191/3686\r2192/3686\r2193/3686\r2194/3686\r2195/3686\r2196/3686\r2197/3686\r2198/3686\r2199/3686\r2200/3686\r2201/3686\r2202/3686\r2203/3686\r2204/3686\r2205/3686\r2206/3686\r2207/3686\r2208/3686\r2209/3686\r2210/3686\r2211/3686\r2212/3686\r2213/3686\r2214/3686\r2215/3686\r2216/3686\r2217/3686\r2218/3686\r2219/3686\r2220/3686\r2221/3686\r2222/3686\r2223/3686\r2224/3686\r2225/3686\r2226/3686\r2227/3686\r2228/3686\r2229/3686\r2230/3686\r2231/3686\r2232/3686\r2233/3686\r2234/3686\r2235/3686\r2236/3686\r2237/3686\r2238/3686\r2239/3686\r2240/3686\r2241/3686\r2242/3686\r2243/3686\r2244/3686\r2245/3686\r2246/3686\r2247/3686\r2248/3686\r2249/3686\r2250/3686\r2251/3686\r2252/3686\r2253/3686\r2254/3686\r2255/3686\r2256/3686\r2257/3686\r2258/3686\r2259/3686\r2260/3686\r2261/3686\r2262/3686\r2263/3686\r2264/3686\r2265/3686\r2266/3686\r2267/3686\r2268/3686\r2269/3686\r2270/3686\r2271/3686\r2272/3686\r2273/3686\r2274/3686\r2275/3686\r2276/3686\r2277/3686\r2278/3686\r2279/3686\r2280/3686\r2281/3686\r2282/3686\r2283/3686\r2284/3686\r2285/3686\r2286/3686\r2287/3686\r2288/3686\r2289/3686\r2290/3686\r2291/3686\r2292/3686\r2293/3686\r2294/3686\r2295/3686\r2296/3686\r2297/3686\r2298/3686\r2299/3686\r2300/3686\r2301/3686\r2302/3686\r2303/3686\r2304/3686\r2305/3686\r2306/3686\r2307/3686\r2308/3686\r2309/3686\r2310/3686\r2311/3686\r2312/3686\r2313/3686\r2314/3686\r2315/3686\r2316/3686\r2317/3686\r2318/3686\r2319/3686\r2320/3686\r2321/3686\r2322/3686\r2323/3686\r2324/3686\r2325/3686\r2326/3686\r2327/3686\r2328/3686\r2329/3686\r2330/3686\r2331/3686\r2332/3686\r2333/3686\r2334/3686\r2335/3686\r2336/3686\r2337/3686\r2338/3686\r2339/3686\r2340/3686\r2341/3686\r2342/3686\r2343/3686\r2344/3686\r2345/3686\r2346/3686\r2347/3686\r2348/3686\r2349/3686\r2350/3686\r2351/3686\r2352/3686\r2353/3686\r2354/3686\r2355/3686\r2356/3686\r2357/3686\r2358/3686\r2359/3686\r2360/3686\r2361/3686\r2362/3686\r2363/3686\r2364/3686\r2365/3686\r2366/3686\r2367/3686\r2368/3686\r2369/3686\r2370/3686\r2371/3686\r2372/3686\r2373/3686\r2374/3686\r2375/3686\r2376/3686\r2377/3686\r2378/3686\r2379/3686\r2380/3686\r2381/3686\r2382/3686\r2383/3686\r2384/3686\r2385/3686\r2386/3686\r2387/3686\r2388/3686\r2389/3686\r2390/3686\r2391/3686\r2392/3686\r2393/3686\r2394/3686\r2395/3686\r2396/3686\r2397/3686\r2398/3686\r2399/3686\r2400/3686\r2401/3686\r2402/3686\r2403/3686\r2404/3686\r2405/3686\r2406/3686\r2407/3686\r2408/3686\r2409/3686\r2410/3686\r2411/3686\r2412/3686\r2413/3686\r2414/3686\r2415/3686\r2416/3686\r2417/3686\r2418/3686\r2419/3686\r2420/3686\r2421/3686\r2422/3686\r2423/3686\r2424/3686\r2425/3686\r2426/3686\r2427/3686\r2428/3686\r2429/3686\r2430/3686\r2431/3686\r2432/3686\r2433/3686\r2434/3686\r2435/3686\r2436/3686\r2437/3686\r2438/3686\r2439/3686\r2440/3686\r2441/3686\r2442/3686\r2443/3686\r2444/3686\r2445/3686\r2446/3686\r2447/3686\r2448/3686\r2449/3686\r2450/3686\r2451/3686\r2452/3686\r2453/3686\r2454/3686\r2455/3686\r2456/3686\r2457/3686\r2458/3686\r2459/3686\r2460/3686\r2461/3686\r2462/3686\r2463/3686\r2464/3686\r2465/3686\r2466/3686\r2467/3686\r2468/3686\r2469/3686\r2470/3686\r2471/3686\r2472/3686\r2473/3686\r2474/3686\r2475/3686\r2476/3686\r2477/3686\r2478/3686\r2479/3686\r2480/3686\r2481/3686\r2482/3686\r2483/3686\r2484/3686\r2485/3686\r2486/3686\r2487/3686\r2488/3686\r2489/3686\r2490/3686\r2491/3686\r2492/3686\r2493/3686\r2494/3686\r2495/3686\r2496/3686\r2497/3686\r2498/3686\r2499/3686\r2500/3686\r2501/3686\r2502/3686\r2503/3686\r2504/3686\r2505/3686\r2506/3686\r2507/3686\r2508/3686\r2509/3686\r2510/3686\r2511/3686\r2512/3686\r2513/3686\r2514/3686\r2515/3686\r2516/3686\r2517/3686\r2518/3686\r2519/3686\r2520/3686\r2521/3686\r2522/3686\r2523/3686\r2524/3686\r2525/3686\r2526/3686\r2527/3686\r2528/3686\r2529/3686\r2530/3686\r2531/3686\r2532/3686\r2533/3686\r2534/3686\r2535/3686\r2536/3686\r2537/3686\r2538/3686\r2539/3686\r2540/3686\r2541/3686\r2542/3686\r2543/3686\r2544/3686\r2545/3686\r2546/3686\r2547/3686\r2548/3686\r2549/3686\r2550/3686\r2551/3686\r2552/3686\r2553/3686\r2554/3686\r2555/3686\r2556/3686\r2557/3686\r2558/3686\r2559/3686\r2560/3686\r2561/3686\r2562/3686\r2563/3686\r2564/3686\r2565/3686\r2566/3686\r2567/3686\r2568/3686\r2569/3686\r2570/3686\r2571/3686\r2572/3686\r2573/3686\r2574/3686\r2575/3686\r2576/3686\r2577/3686\r2578/3686\r2579/3686\r2580/3686\r2581/3686\r2582/3686\r2583/3686\r2584/3686\r2585/3686\r2586/3686\r2587/3686\r2588/3686\r2589/3686\r2590/3686\r2591/3686\r2592/3686\r2593/3686\r2594/3686\r2595/3686\r2596/3686\r2597/3686\r2598/3686\r2599/3686\r2600/3686\r2601/3686\r2602/3686\r2603/3686\r2604/3686\r2605/3686\r2606/3686\r2607/3686\r2608/3686\r2609/3686\r2610/3686\r2611/3686\r2612/3686\r2613/3686\r2614/3686\r2615/3686\r2616/3686\r2617/3686\r2618/3686\r2619/3686\r2620/3686\r2621/3686\r2622/3686\r2623/3686\r2624/3686\r2625/3686\r2626/3686\r2627/3686\r2628/3686\r2629/3686\r2630/3686\r2631/3686\r2632/3686\r2633/3686\r2634/3686\r2635/3686\r2636/3686\r2637/3686\r2638/3686\r2639/3686\r2640/3686\r2641/3686\r2642/3686\r2643/3686\r2644/3686\r2645/3686\r2646/3686\r2647/3686\r2648/3686\r2649/3686\r2650/3686\r2651/3686\r2652/3686\r2653/3686\r2654/3686\r2655/3686\r2656/3686\r2657/3686\r2658/3686\r2659/3686\r2660/3686\r2661/3686\r2662/3686\r2663/3686\r2664/3686\r2665/3686\r2666/3686\r2667/3686\r2668/3686\r2669/3686\r2670/3686\r2671/3686\r2672/3686\r2673/3686\r2674/3686\r2675/3686\r2676/3686\r2677/3686\r2678/3686\r2679/3686\r2680/3686\r2681/3686\r2682/3686\r2683/3686\r2684/3686\r2685/3686\r2686/3686\r2687/3686\r2688/3686\r2689/3686\r2690/3686\r2691/3686\r2692/3686\r2693/3686\r2694/3686\r2695/3686\r2696/3686\r2697/3686\r2698/3686\r2699/3686\r2700/3686\r2701/3686\r2702/3686\r2703/3686\r2704/3686\r2705/3686\r2706/3686\r2707/3686\r2708/3686\r2709/3686\r2710/3686\r2711/3686\r2712/3686\r2713/3686\r2714/3686\r2715/3686\r2716/3686\r2717/3686\r2718/3686\r2719/3686\r2720/3686\r2721/3686\r2722/3686\r2723/3686\r2724/3686\r2725/3686\r2726/3686\r2727/3686\r2728/3686\r2729/3686\r2730/3686\r2731/3686\r2732/3686\r2733/3686\r2734/3686\r2735/3686\r2736/3686\r2737/3686\r2738/3686\r2739/3686\r2740/3686\r2741/3686\r2742/3686\r2743/3686\r2744/3686\r2745/3686\r2746/3686\r2747/3686\r2748/3686\r2749/3686\r2750/3686\r2751/3686\r2752/3686\r2753/3686\r2754/3686\r2755/3686\r2756/3686\r2757/3686\r2758/3686\r2759/3686\r2760/3686\r2761/3686\r2762/3686\r2763/3686\r2764/3686\r2765/3686\r2766/3686\r2767/3686\r2768/3686\r2769/3686\r2770/3686\r2771/3686\r2772/3686\r2773/3686\r2774/3686\r2775/3686\r2776/3686\r2777/3686\r2778/3686\r2779/3686\r2780/3686\r2781/3686\r2782/3686\r2783/3686\r2784/3686\r2785/3686\r2786/3686\r2787/3686\r2788/3686\r2789/3686\r2790/3686\r2791/3686\r2792/3686\r2793/3686\r2794/3686\r2795/3686\r2796/3686\r2797/3686\r2798/3686\r2799/3686\r2800/3686\r2801/3686\r2802/3686\r2803/3686\r2804/3686\r2805/3686\r2806/3686\r2807/3686\r2808/3686\r2809/3686\r2810/3686\r2811/3686\r2812/3686\r2813/3686\r2814/3686\r2815/3686\r2816/3686\r2817/3686\r2818/3686\r2819/3686\r2820/3686\r2821/3686\r2822/3686\r2823/3686\r2824/3686\r2825/3686\r2826/3686\r2827/3686\r2828/3686\r2829/3686\r2830/3686\r2831/3686\r2832/3686\r2833/3686\r2834/3686\r2835/3686\r2836/3686\r2837/3686\r2838/3686\r2839/3686\r2840/3686\r2841/3686\r2842/3686\r2843/3686\r2844/3686\r2845/3686\r2846/3686\r2847/3686\r2848/3686\r2849/3686\r2850/3686\r2851/3686\r2852/3686\r2853/3686\r2854/3686\r2855/3686\r2856/3686\r2857/3686\r2858/3686\r2859/3686\r2860/3686\r2861/3686\r2862/3686\r2863/3686\r2864/3686\r2865/3686\r2866/3686\r2867/3686\r2868/3686\r2869/3686\r2870/3686\r2871/3686\r2872/3686\r2873/3686\r2874/3686\r2875/3686\r2876/3686\r2877/3686\r2878/3686\r2879/3686\r2880/3686\r2881/3686\r2882/3686\r2883/3686\r2884/3686\r2885/3686\r2886/3686\r2887/3686\r2888/3686\r2889/3686\r2890/3686\r2891/3686\r2892/3686\r2893/3686\r2894/3686\r2895/3686\r2896/3686\r2897/3686\r2898/3686\r2899/3686\r2900/3686\r2901/3686\r2902/3686\r2903/3686\r2904/3686\r2905/3686\r2906/3686\r2907/3686\r2908/3686\r2909/3686\r2910/3686\r2911/3686\r2912/3686\r2913/3686\r2914/3686\r2915/3686\r2916/3686\r2917/3686\r2918/3686\r2919/3686\r2920/3686\r2921/3686\r2922/3686\r2923/3686\r2924/3686\r2925/3686\r2926/3686\r2927/3686\r2928/3686\r2929/3686\r2930/3686\r2931/3686\r2932/3686\r2933/3686\r2934/3686\r2935/3686\r2936/3686\r2937/3686\r2938/3686\r2939/3686\r2940/3686\r2941/3686\r2942/3686\r2943/3686\r2944/3686\r2945/3686\r2946/3686\r2947/3686\r2948/3686\r2949/3686\r2950/3686\r2951/3686\r2952/3686\r2953/3686\r2954/3686\r2955/3686\r2956/3686\r2957/3686\r2958/3686\r2959/3686\r2960/3686\r2961/3686\r2962/3686\r2963/3686\r2964/3686\r2965/3686\r2966/3686\r2967/3686\r2968/3686\r2969/3686\r2970/3686\r2971/3686\r2972/3686\r2973/3686\r2974/3686\r2975/3686\r2976/3686\r2977/3686\r2978/3686\r2979/3686\r2980/3686\r2981/3686\r2982/3686\r2983/3686\r2984/3686\r2985/3686\r2986/3686\r2987/3686\r2988/3686\r2989/3686\r2990/3686\r2991/3686\r2992/3686\r2993/3686\r2994/3686\r2995/3686\r2996/3686\r2997/3686\r2998/3686\r2999/3686\r3000/3686\r3001/3686\r3002/3686\r3003/3686\r3004/3686\r3005/3686\r3006/3686\r3007/3686\r3008/3686\r3009/3686\r3010/3686\r3011/3686\r3012/3686\r3013/3686\r3014/3686\r3015/3686\r3016/3686\r3017/3686\r3018/3686\r3019/3686\r3020/3686\r3021/3686\r3022/3686\r3023/3686\r3024/3686\r3025/3686\r3026/3686\r3027/3686\r3028/3686\r3029/3686\r3030/3686\r3031/3686\r3032/3686\r3033/3686\r3034/3686\r3035/3686\r3036/3686\r3037/3686\r3038/3686\r3039/3686\r3040/3686\r3041/3686\r3042/3686\r3043/3686\r3044/3686\r3045/3686\r3046/3686\r3047/3686\r3048/3686\r3049/3686\r3050/3686\r3051/3686\r3052/3686\r3053/3686\r3054/3686\r3055/3686\r3056/3686\r3057/3686\r3058/3686\r3059/3686\r3060/3686\r3061/3686\r3062/3686\r3063/3686\r3064/3686\r3065/3686\r3066/3686\r3067/3686\r3068/3686\r3069/3686\r3070/3686\r3071/3686\r3072/3686\r3073/3686\r3074/3686\r3075/3686\r3076/3686\r3077/3686\r3078/3686\r3079/3686\r3080/3686\r3081/3686\r3082/3686\r3083/3686\r3084/3686\r3085/3686\r3086/3686\r3087/3686\r3088/3686\r3089/3686\r3090/3686\r3091/3686\r3092/3686\r3093/3686\r3094/3686\r3095/3686\r3096/3686\r3097/3686\r3098/3686\r3099/3686\r3100/3686\r3101/3686\r3102/3686\r3103/3686\r3104/3686\r3105/3686\r3106/3686\r3107/3686\r3108/3686\r3109/3686\r3110/3686\r3111/3686\r3112/3686\r3113/3686\r3114/3686\r3115/3686\r3116/3686\r3117/3686\r3118/3686\r3119/3686\r3120/3686\r3121/3686\r3122/3686\r3123/3686\r3124/3686\r3125/3686\r3126/3686\r3127/3686\r3128/3686\r3129/3686\r3130/3686\r3131/3686\r3132/3686\r3133/3686\r3134/3686\r3135/3686\r3136/3686\r3137/3686\r3138/3686\r3139/3686\r3140/3686\r3141/3686\r3142/3686\r3143/3686\r3144/3686\r3145/3686\r3146/3686\r3147/3686\r3148/3686\r3149/3686\r3150/3686\r3151/3686\r3152/3686\r3153/3686\r3154/3686\r3155/3686\r3156/3686\r3157/3686\r3158/3686\r3159/3686\r3160/3686\r3161/3686\r3162/3686\r3163/3686\r3164/3686\r3165/3686\r3166/3686\r3167/3686\r3168/3686\r3169/3686\r3170/3686\r3171/3686\r3172/3686\r3173/3686\r3174/3686\r3175/3686\r3176/3686\r3177/3686\r3178/3686\r3179/3686\r3180/3686\r3181/3686\r3182/3686\r3183/3686\r3184/3686\r3185/3686\r3186/3686\r3187/3686\r3188/3686\r3189/3686\r3190/3686\r3191/3686\r3192/3686\r3193/3686\r3194/3686\r3195/3686\r3196/3686\r3197/3686\r3198/3686\r3199/3686\r3200/3686\r3201/3686\r3202/3686\r3203/3686\r3204/3686\r3205/3686\r3206/3686\r3207/3686\r3208/3686\r3209/3686\r3210/3686\r3211/3686\r3212/3686\r3213/3686\r3214/3686\r3215/3686\r3216/3686\r3217/3686\r3218/3686\r3219/3686\r3220/3686\r3221/3686\r3222/3686\r3223/3686\r3224/3686\r3225/3686\r3226/3686\r3227/3686\r3228/3686\r3229/3686\r3230/3686\r3231/3686\r3232/3686\r3233/3686\r3234/3686\r3235/3686\r3236/3686\r3237/3686\r3238/3686\r3239/3686\r3240/3686\r3241/3686\r3242/3686\r3243/3686\r3244/3686\r3245/3686\r3246/3686\r3247/3686\r3248/3686\r3249/3686\r3250/3686\r3251/3686\r3252/3686\r3253/3686\r3254/3686\r3255/3686\r3256/3686\r3257/3686\r3258/3686\r3259/3686\r3260/3686\r3261/3686\r3262/3686\r3263/3686\r3264/3686\r3265/3686\r3266/3686\r3267/3686\r3268/3686\r3269/3686\r3270/3686\r3271/3686\r3272/3686\r3273/3686\r3274/3686\r3275/3686\r3276/3686\r3277/3686\r3278/3686\r3279/3686\r3280/3686\r3281/3686\r3282/3686\r3283/3686\r3284/3686\r3285/3686\r3286/3686\r3287/3686\r3288/3686\r3289/3686\r3290/3686\r3291/3686\r3292/3686\r3293/3686\r3294/3686\r3295/3686\r3296/3686\r3297/3686\r3298/3686\r3299/3686\r3300/3686\r3301/3686\r3302/3686\r3303/3686\r3304/3686\r3305/3686\r3306/3686\r3307/3686\r3308/3686\r3309/3686\r3310/3686\r3311/3686\r3312/3686\r3313/3686\r3314/3686\r3315/3686\r3316/3686\r3317/3686\r3318/3686\r3319/3686\r3320/3686\r3321/3686\r3322/3686\r3323/3686\r3324/3686\r3325/3686\r3326/3686\r3327/3686\r3328/3686\r3329/3686\r3330/3686\r3331/3686\r3332/3686\r3333/3686\r3334/3686\r3335/3686\r3336/3686\r3337/3686\r3338/3686\r3339/3686\r3340/3686\r3341/3686\r3342/3686\r3343/3686\r3344/3686\r3345/3686\r3346/3686\r3347/3686\r3348/3686\r3349/3686\r3350/3686\r3351/3686\r3352/3686\r3353/3686\r3354/3686\r3355/3686\r3356/3686\r3357/3686\r3358/3686\r3359/3686\r3360/3686\r3361/3686\r3362/3686\r3363/3686\r3364/3686\r3365/3686\r3366/3686\r3367/3686\r3368/3686\r3369/3686\r3370/3686\r3371/3686\r3372/3686\r3373/3686\r3374/3686\r3375/3686\r3376/3686\r3377/3686\r3378/3686\r3379/3686\r3380/3686\r3381/3686\r3382/3686\r3383/3686\r3384/3686\r3385/3686\r3386/3686\r3387/3686\r3388/3686\r3389/3686\r3390/3686\r3391/3686\r3392/3686\r3393/3686\r3394/3686\r3395/3686\r3396/3686\r3397/3686\r3398/3686\r3399/3686\r3400/3686\r3401/3686\r3402/3686\r3403/3686\r3404/3686\r3405/3686\r3406/3686\r3407/3686\r3408/3686\r3409/3686\r3410/3686\r3411/3686\r3412/3686\r3413/3686\r3414/3686\r3415/3686\r3416/3686\r3417/3686\r3418/3686\r3419/3686\r3420/3686\r3421/3686\r3422/3686\r3423/3686\r3424/3686\r3425/3686\r3426/3686\r3427/3686\r3428/3686\r3429/3686\r3430/3686\r3431/3686\r3432/3686\r3433/3686\r3434/3686\r3435/3686\r3436/3686\r3437/3686\r3438/3686\r3439/3686\r3440/3686\r3441/3686\r3442/3686\r3443/3686\r3444/3686\r3445/3686\r3446/3686\r3447/3686\r3448/3686\r3449/3686\r3450/3686\r3451/3686\r3452/3686\r3453/3686\r3454/3686\r3455/3686\r3456/3686\r3457/3686\r3458/3686\r3459/3686\r3460/3686\r3461/3686\r3462/3686\r3463/3686\r3464/3686\r3465/3686\r3466/3686\r3467/3686\r3468/3686\r3469/3686\r3470/3686\r3471/3686\r3472/3686\r3473/3686\r3474/3686\r3475/3686\r3476/3686\r3477/3686\r3478/3686\r3479/3686\r3480/3686\r3481/3686\r3482/3686\r3483/3686\r3484/3686\r3485/3686\r3486/3686\r3487/3686\r3488/3686\r3489/3686\r3490/3686\r3491/3686\r3492/3686\r3493/3686\r3494/3686\r3495/3686\r3496/3686\r3497/3686\r3498/3686\r3499/3686\r3500/3686\r3501/3686\r3502/3686\r3503/3686\r3504/3686\r3505/3686\r3506/3686\r3507/3686\r3508/3686\r3509/3686\r3510/3686\r3511/3686\r3512/3686\r3513/3686\r3514/3686\r3515/3686\r3516/3686\r3517/3686\r3518/3686\r3519/3686\r3520/3686\r3521/3686\r3522/3686\r3523/3686\r3524/3686\r3525/3686\r3526/3686\r3527/3686\r3528/3686\r3529/3686\r3530/3686\r3531/3686\r3532/3686\r3533/3686\r3534/3686\r3535/3686\r3536/3686\r3537/3686\r3538/3686\r3539/3686\r3540/3686\r3541/3686\r3542/3686\r3543/3686\r3544/3686\r3545/3686\r3546/3686\r3547/3686\r3548/3686\r3549/3686\r3550/3686\r3551/3686\r3552/3686\r3553/3686\r3554/3686\r3555/3686\r3556/3686\r3557/3686\r3558/3686\r3559/3686\r3560/3686\r3561/3686\r3562/3686\r3563/3686\r3564/3686\r3565/3686\r3566/3686\r3567/3686\r3568/3686\r3569/3686\r3570/3686\r3571/3686\r3572/3686\r3573/3686\r3574/3686\r3575/3686\r3576/3686\r3577/3686\r3578/3686\r3579/3686\r3580/3686\r3581/3686\r3582/3686\r3583/3686\r3584/3686\r3585/3686\r3586/3686\r3587/3686\r3588/3686\r3589/3686\r3590/3686\r3591/3686\r3592/3686\r3593/3686\r3594/3686\r3595/3686\r3596/3686\r3597/3686\r3598/3686\r3599/3686\r3600/3686\r3601/3686\r3602/3686\r3603/3686\r3604/3686\r3605/3686\r3606/3686\r3607/3686\r3608/3686\r3609/3686\r3610/3686\r3611/3686\r3612/3686\r3613/3686\r3614/3686\r3615/3686\r3616/3686\r3617/3686\r3618/3686\r3619/3686\r3620/3686\r3621/3686\r3622/3686\r3623/3686\r3624/3686\r3625/3686\r3626/3686\r3627/3686\r3628/3686\r3629/3686\r3630/3686\r3631/3686\r3632/3686\r3633/3686\r3634/3686\r3635/3686\r3636/3686\r3637/3686\r3638/3686\r3639/3686\r3640/3686\r3641/3686\r3642/3686\r3643/3686\r3644/3686\r3645/3686\r3646/3686\r3647/3686\r3648/3686\r3649/3686\r3650/3686\r3651/3686\r3652/3686\r3653/3686\r3654/3686\r3655/3686\r3656/3686\r3657/3686\r3658/3686\r3659/3686\r3660/3686\r3661/3686\r3662/3686\r3663/3686\r3664/3686\r3665/3686\r3666/3686\r3667/3686\r3668/3686\r3669/3686\r3670/3686\r3671/3686\r3672/3686\r3673/3686\r3674/3686\r3675/3686\r3676/3686\r3677/3686\r3678/3686\r3679/3686\r3680/3686\r3681/3686\r3682/3686\r3683/3686\r3684/3686\r3685/3686\r3686/3686\r\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FctUq65c1cOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fix error when using keras 2.2.5\n",
        "!echo \"from .load_backend import control_flow_ops\"$'\\n'\"from .load_backend import set_image_dim_ordering\"$'\\n'\"$(cat /usr/local/lib/python3.6/dist-packages/keras/backend/__init__.py)\" > /usr/local/lib/python3.6/dist-packages/keras/backend/__init__.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rQw9sVjwJCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47e9e479-1961-4be2-f647-e444c584d71a"
      },
      "source": [
        "!python keras-yolo3/train.py --anchor keras-yolo3/model_data/yolo_anchors.txt --weight pretrained/darknet53.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-12 13:02:58.575485: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-01-12 13:02:58.575850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ca2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-12 13:02:58.575895: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-12 13:02:58.578055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-12 13:02:58.580116: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-01-12 13:02:58.580158: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eb3d40244eeb): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Create YOLOv3 model with 9 anchors and 37 classes.\n",
            "Load weights pretrained/darknet53.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3351: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Train on 2686 samples, val on 298 samples, with batch size 32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/50\n",
            "2020-01-12 13:03:20.105087: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-01-12 13:03:20.299424: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-01-12 13:03:21.304251: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-01-12 13:03:21.495623: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-01-12 13:03:23.609956: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 708837376 exceeds 10% of system memory.\n",
            "2020-01-12 13:03:29.596673: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 712249344 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 1594982400 bytes == 0xdc520000 @  0x7f63f1a921e7 0x7f63b7c38192 0x7f63bb80d16a 0x7f63bb850019 0x7f63bb8521e7 0x7f63bb8529f1 0x7f63bb8988db 0x7f63bb898f7c 0x7f63bb89a33c 0x7f63b30b0f36 0x7f63b30a3585 0x7f63b31616b9 0x7f63b315ed88 0x7f63f037466f 0x7f63f14566db 0x7f63f178f88f\n",
            "tcmalloc: large alloc 1594982400 bytes == 0xc6fde000 @  0x7f63f1a921e7 0x7f63b7c38192 0x7f63bb80d16a 0x7f63bb850019 0x7f63bb8521e7 0x7f63bb8529f1 0x7f63bb8988db 0x7f63bb898f7c 0x7f63bb89a33c 0x7f63b30b0f36 0x7f63b30a3585 0x7f63b31616b9 0x7f63b315ed88 0x7f63f037466f 0x7f63f14566db 0x7f63f178f88f\n",
            " 1/83 [..............................] - ETA: 2:17:08 - loss: 8929.43262020-01-12 13:04:55.214216: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 708837376 exceeds 10% of system memory.\n",
            "2020-01-12 13:04:59.963814: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 712249344 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 1594982400 bytes == 0x1c82be000 @  0x7f63f1a921e7 0x7f63b7c38192 0x7f63bb80d16a 0x7f63bb850019 0x7f63bb8521e7 0x7f63bb8529f1 0x7f63bb8988db 0x7f63bb898f7c 0x7f63bb89a33c 0x7f63b30b0f36 0x7f63b30a3585 0x7f63b31616b9 0x7f63b315ed88 0x7f63f037466f 0x7f63f14566db 0x7f63f178f88f\n",
            "tcmalloc: large alloc 1594982400 bytes == 0x1c82be000 @  0x7f63f1a921e7 0x7f63b7c38192 0x7f63bb80d16a 0x7f63bb850019 0x7f63bb8521e7 0x7f63bb8529f1 0x7f63bb8988db 0x7f63bb898f7c 0x7f63bb89a33c 0x7f63b30b0f36 0x7f63b30a3585 0x7f63b31616b9 0x7f63b315ed88 0x7f63f037466f 0x7f63f14566db 0x7f63f178f88f\n",
            " 2/83 [..............................] - ETA: 1:46:43 - loss: 8667.65142020-01-12 13:05:52.907161: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 708837376 exceeds 10% of system memory.\n",
            "82/83 [============================>.] - ETA: 55s - loss: 1932.2596 2020-01-12 14:20:39.225282: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2020-01-12 14:20:39.865103: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "83/83 [==============================] - 5175s 62s/step - loss: 1914.2458 - val_loss: 5143.5484\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/50\n",
            "82/83 [============================>.] - ETA: 56s - loss: 265.9474 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sUYyC800QX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}